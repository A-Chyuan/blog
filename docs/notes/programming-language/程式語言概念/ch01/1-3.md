# Language Evaluation Criteria

- **Readability**: The ease with which programs can be *read* and *understood*.
- **Writability**: The ease with which a language can be used to *create programs*.
- **Reliability**: Conformance to specifications (i.e., performs to its specifications).
- **Cost**: The ultimate total cost.

## Readability

One of the most important criteria for judging a programming language is the ease with which programs can be read and understood.

- Before 1970, software development was largely thought of in terms of writing code.
- The primary positive characteristic of programming languages was efficiency.
- Language constructs were designed more from the point of view of the computer than of the computer users.

In the 1970s, the *software life-cycle concept* was developed.

- **Coding** was relegated to a much smaller role.
- **Maintenance** was recognized as a *major part* of the cycle, particularly in terms of cost.

Because ease of maintenance is determined in large part by the readability of programs.

- Readability became an important measure of the quality of programs and programming languages.
- From a focus on machine orientation to a focus on human orientation.

Readability must be considered in the context of the problem domain.

- If a program that describes a computation is written in a language not designed for such use, the program may be unnatural and convoluted, making it unusually difficult to read.

### Overall Simplicity

The overall simplicity of a programming language strongly affects its readability.

- A language with a large number of basic constructs is more difficult to learn than one with a smaller number.
- Programmers who must use a large language often learn a subset of the language and ignore its other features.

Readability problems occur whenever the program’s author has learned a different subset from that subset with which the reader is familiar.

- Minimal **feature multiplicity**—that is, having more than one way to accomplish a particular operation.

<div class="alert-example">

In Java, a user can increment a simple integer variable in four different ways:

```java
count = count + 1
count += 1
count++
++count
```

Although the last two statements have slightly different meanings from each other and from the others in some contexts, all of them have the same meaning when used as stand-alone expressions. These variations are discussed in Chapter 7.

</div>

- Minimal **operator overloading**, in which a single operator symbol has more than one meaning.

    Although this is often useful, it can lead to reduced readability if users are allowed to create their own overloading and do not do it sensibly.

<div class="alert-attention">

?> Simplicity in languages can be carried too far.

For example, the form and meaning of most *assembly language* statements are models of simplicity. This very simplicity, however, makes assembly language programs less readable. Because

- They lack more complex control statements, program structure is less obvious;
- The statements are simple, far more of them are required than in equivalent programs in a high-level language.

</div>

### Orthogonality

**Orthogonality** in a programming language means that

- A relatively small set of primitive constructs can be combined in a relatively small number of ways to build the control and data structures of the language.
- Furthermore, every possible combination of primitives is legal and meaningful.

Orthogonality is closely related to simplicity:

- The more orthogonal the design of a language, the fewer exceptions the language rules require.
- Fewer exceptions mean a higher degree of regularity in the design, which makes the language easier to learn, read, and understand.

Simplicity in a language, therefore, is at least in part the result of

- a combination of a relatively small number of primitive constructs and
- a limited use of the concept of orthogonality.

<div class="alert-example">

?> Consider data types.

Suppose a language has

- Four primitive data types (integer, float, double, and character).
- Two type operators (array and pointer).

The two type operators can be applied to themselves and the four primitive data types. A large number of data structures can be defined.

</div>

<div class="alert-example">

We can illustrate the use of orthogonality as a design concept by comparing one aspect of the assembly languages of the IBM mainframe computers and the VAX series of minicomputers.

We consider a single simple situation:

?> Adding two 32-bit integer values that reside in either memory or registers and replacing one of the two values with the sum.

- The IBM mainframes have two instructions for this purpose, which have the forms

    ```assembly
    A Reg1, memory_cell
    AR Reg1, Reg2
    ```

    ```algorithm
    \begin{algorithm}
    \caption{Semantics}
    \begin{algorithmic}

    \state Reg1 ← contents(Reg1) + contents(memory\_cell)
    \state Reg1 ← contents(Reg1) + contents(Reg2)

    \end{algorithmic}
    \end{algorithm}
    ```

    where `Reg1` and `Reg2` represent registers.

- The VAX addition instruction for 32-bit integer values is

    ```assembly
    ADDL operand_1, operand_2
    ```

    ```algorithm
    \begin{algorithm}
    \caption{Semantics}
    \begin{algorithmic}

    \state operand\_2 ← contents(operand\_1) + contents(operand\_2)

    \end{algorithmic}
    \end{algorithm}
    ```

    In this case, either operand can be a register or a memory cell.

***Conclusion***

- The VAX instruction design is orthogonal.

    - A single instruction can use either registers or memory cells as its operands.
    - There are two ways to specify operands, which can be combined in all possible ways.

- The IBM design is not orthogonal.

    - Only two out of four operand combinations possibilities are legal, and the two require different instructions, `A` and `AR`.

- The IBM design is more restricted and therefore less writable.

    - For example, you cannot add two values and store the sum in a memory location.
    - Furthermore, the IBM design is more difficult to learn because of the restrictions and the additional instruction.

</div>

<div class="alert-example">

?> In high-level languages like C, a lack of orthogonality can be seen in how certain features depend on context.

Consider the C expression

```c
a + b
```

- This expression often means that the values of `a` and `b` are fetched and added together.
- However, if `a` happens to be a pointer and `b` is an integer, it affects the value of `b`.

    - If `a` points to a float value that occupies four bytes.
    - The value of `b` must *be scaled*—in this case multiplied by 4—before it is added to `a`.
    - Therefore, <mark>the type of `a` affects the treatment of the value of `b`. The context of `b` affects its meaning.</mark>

在這個表達式中，如何看待 `b` 的值依賴於 `a` 的類型，而非單獨、正交地操作。這種依賴

- 使得語句的意圖變得不直觀，導致程式的可預測性下降。
- 缺乏正交性，讓語言的某個特性（加法操作）變得不再純粹，受其他上下文的影響。

</div>

<div class="alert-attention">

?> A lack of orthogonality leads to exceptions to the rules of the language.

For example, in a programming language that supports pointers, it should be possible to define a pointer to point to any specific type defined in the language.

However, if pointers are not allowed to point to arrays, many potentially useful user-defined data structures cannot be defined.

</div>

<div class="alert-attention">

?> Too much orthogonality can also cause problems.

Perhaps the most orthogonal programming language is ALGOL 68.

- Every language construct in ALGOL 68 has a type, and there are no restrictions on those types.
- In addition, most constructs produce values.
- This combinational freedom allows extremely complex constructs.

For example, a conditional can appear as the left side of an assignment, along with declarations and other assorted statements, as long as the result is an address.

- This extreme form of orthogonality leads to unnecessary complexity.
- Furthermore, because languages require a large number of primitives, a high degree of orthogonality results in an explosion of combinations.

So, <mark>even if the combinations are simple, their sheer numbers lead to complexity.</mark>

</div>

#### Functional Languages

Some believe that functional languages offer a good combination of *simplicity* and *orthogonality*.

- A functional language, such as Lisp, is one in which computations are made primarily by applying functions to given parameters.
- In contrast, in imperative languages such as C, C++, and Java, computations are usually specified with variables and assignment statements.

Functional languages offer potentially the greatest overall simplicity.

- Because they can accomplish everything with a single construct, the function call, which can be combined simply with other function calls.
- This simple elegance is the reason why some language researchers are attracted to functional languages as the primary alternative to complex nonfunctional languages such as Java.
- Other factors, the most important of which is probably efficiency, however, have prevented functional languages from becoming more widely used.

### Data Types

The presence of adequate facilities for defining **data types** and **data structures** in a language is another significant aid to readability.

<div class="alert-example">

- Suppose a numeric type is used for an indicator flag because there is no Boolean type in the language. For example, in the original version of C, we might have an assignment such as the following:

  ```c
  // The meaning of this statement is unclear
  timeout = 1
  ```

- In a language that includes Boolean types, we would have the following:

  ```c
  // The meaning of this statement is perfectly clear
  timeout = true
  ```

</div>

### Syntax Design

The syntax, or form, of the elements of a language has a significant effect on the readability of programs.

#### Special Words

- Program appearance and thus program readability are strongly influenced by the forms of a language’s special words (for example, `while`, `class`, and `for`).
- Especially important is the method of forming compound statements, or statement groups, primarily in control constructs.

<div class="alert-example">

?> Some languages have used matching pairs of special words or symbols to form groups.

C and its descendants use braces (`{ ... }`) to specify compound statements.

- All of these languages have diminished readability.
- Statement groups are always terminated in the *same* way.
- It is difficult to determine which group is being ended when an end or a right brace appears.

Fortran 95 and Ada make this clearer by using a *distinct* closing syntax for each type of statement group. For example, Ada uses

- `end if` to terminate a selection construct.
- `end loop` to terminate a loop construct.

</div>

<div class="alert-attention">

?> Conflict between simplicity and readability:

- Simplicity results in fewer reserved words, as seen in Java.
- Greater readability can result from using more reserved words, as in Ada.

</div>

<div class="alert-attention">

?> If the special words of a language can be used as names for program variables, the resulting programs can be very confusing.

In Fortran 95, special words, such as `Do` and `End`, are legal variable names, so the appearance of these words in a program may or may not connote something special.

</div>

#### Form and Meaning

- Designing statements so that their appearance at least partially indicates their purpose is an obvious aid to readability.
- Semantics, or meaning, should follow directly from syntax, or form.

<div class="alert-example">

?> The appearance of UNIX shell commands does not always clearly indicate their function.

For example, the meaning of the UNIX command `grep` can be deciphered only through prior knowledge. The appearance of `grep` connotes nothing to UNIX beginners.

Perhaps cleverness and familiarity with the UNIX editor, *ed*. (In ed, the command `/regular_expression/` searches for a substring that matches the regular expression.

- Preceding this with `g` makes it a global command, specifying that the scope of the search is the whole file being edited.
- Following the command with `p` specifies that lines with the matching substring are to be printed.

So `g/regular_expression/p`, which can obviously be abbreviated as `grep`, prints all lines in a file that contain substrings that match its operand, which is a regular expression.)

</div>

<div class="alert-example">

?> Two language constructs that are identical or similar in appearance but have different meanings, depending perhaps on context.

In C, the meaning of the reserved word `static` depends on the context of its appearance.

- If used on the definition of a variable inside a function, it means the variable is created at compile time.
- If used on the definition of a variable that is outside all functions, then it means the variable is visible only in the file in which its definition appears; that is, it is not exported from that file.

</div>

## Writability

Writability is a measure of how easily a language can be used to *create programs* for a chosen problem domain.

Most of the language characteristics that affect readability also affect writability:

- The process of writing a program requires the programmer frequently to *reread* the part of the program that is already written.

As is the case with readability, writability must be considered in the context of the target problem domain of a language.

- It simply is not fair to compare the writability of two languages in the realm of a particular application when one was designed for that application and the other was not.

<div class="alert-example">

The writabilities of Visual BASIC and C are dramatically different.

- Visual BASIC is ideal for creating programs with a graphical user interface (GUI).
- C was designed for writing systems programs, such as operating systems.

</div>

### Simplicity and Orthogonality

If a language has a large number of different constructs, some programmers who use the language might not be familiar with all of them. This situation can lead to

- A misuse of some features.
- A disuse of others that may be either more elegant or more efficient, or both, than those that are used.
- It may even be possible to use unknown features accidentally, with bizarre results.

***The Advantage of Fewer Primitives***

Therefore, a smaller number of primitive constructs and a consistent set of rules for combining them (that is, orthogonality) is much better than simply having a large number of primitives.

- Learning only a simple set of primitive constructs.
- A programmer can design solutions to complex problems.

On the other hand, too much orthogonality can be a detriment to writability:

- Nearly any combination of primitives is legal.
- Errors in programs can go undetected.
- Cannot be discovered by the compiler.

### Expressivity

A language has relatively convenient, rather than cumbersome, ways of specifying computations.

<div class="alert-example">

In a language such as APL, it means that there are very powerful operators that allow a great deal of computation to be accomplished with a very small program.

The following expression finds all prime numbers from 1 to R. In both time and space, the calculation complexity is $O(R^2)$ (in Big O notation).

```apl
(~R∊R∘.×R)/R←1↓⍳R
```

</div>

<div class="alert-example">

- In C, the notation `count++` is more convenient and shorter than `count = count + 1`.
- The `and` `then` Boolean operator in Ada is a convenient way of specifying short-circuit evaluation of a Boolean expression.
- The inclusion of the `for` statement in Java makes writing counting loops easier than with the use of `while`, which is also possible.

All of these increase the writability of a language.

</div>

## Reliability

A program is said to be reliable if it performs to its specifications under all conditions.

### Type Checking

**Type checking** is simply testing for type errors in a given program, either by the compiler or during program execution.

- Type checking is an important factor in language reliability.
- Because *run-time* type checking is expensive, *compile-time* type checking is more desirable.
- Furthermore, the earlier errors in programs are detected, the less expensive it is to make the required repairs.

<div class="alert-example">

The design of Java requires checks of the types of nearly all variables and expressions at compile time. This virtually eliminates type errors at run time in Java programs.

Types and type checking are discussed in depth in Chapter 6.

</div>

<div class="alert-example">

One example of how failure to type check, at either compile time or run time, has led to countless program errors is the use of subprogram parameters in the original C language.

- In this language, the type of an actual parameter in a function call was not checked to determine whether its type matched that of the corresponding formal parameter in the function.
- An `int` type variable could be used as an actual parameter in a call to a function that expected a `float` type as its formal parameter.
- Neither the compiler nor the run-time system would detect the inconsistency.

For example, because the bit string that represents the integer 23 is essentially unrelated to the bit string that represents a floating-point 23, if an integer 23 is sent to a function that expects a floating-point parameter, any uses of the parameter in the function will produce nonsense. Furthermore, such problems are often difficult to diagnose.

The current version of C has eliminated this problem by requiring all parameters to be type checked.

Subprograms and parameter-passing techniques are discussed in Chapter 9.

</div>

### Exception Handling

The ability of a program to intercept run-time errors (as well as other unusual conditions detectable by the program), take corrective measures, and then continue is an obvious aid to reliability. This language facility is called **exception handling**.

- Ada, C++, Java, and C# include extensive capabilities for exception handling.
- But such facilities are practically nonexistent in some widely used languages, for example, C.

Exception handling is discussed in Chapter 14.

### Aliasing

- Loosely defined, **aliasing** is having two or more distinct names in a program that can be used to access the same memory cell.
- It is now generally accepted that aliasing is a *dangerous feature* in a programming language.

<div class="alert-example">

Most programming languages allow some kind of aliasing—for example,

- Two *pointers* (or *references*) set to point to the same variable, which is possible in most languages.
- In such a program, the programmer must always remember that changing the value pointed to by one of the two changes the value referenced by the other.

</div>

In some languages, aliasing is used to

- Overcome deficiencies in the language’s data abstraction facilities.
- Other languages greatly restrict aliasing to increase their reliability.

Some kinds of aliasing, as described in Chapters 5 and 9, can be prohibited by the design of a language.

### Readability and Writability

Both readability and writability influence reliability:

- A program written in a language that does not support natural ways to express the required algorithms will necessarily use unnatural approaches.
- Unnatural approaches are less likely to be correct for all possible situations.
- The easier a program is to write, the more likely it is to be correct.

Readability affects reliability in both the writing and maintenance phases of the life cycle.

- Programs that are difficult to read are difficult both to write and to modify.

## Cost

The total cost of a programming language is a function of many of its characteristics:

1. The cost of **training programmers** to use the language:

    - Which is a function of the simplicity and orthogonality of the language and the experience of the programmers.
    - Although more powerful languages are not necessarily more difficult to learn, they often are.

2. The cost of **writing programs** in the language:

    - This is a function of the writability of the language, which depends in part on its closeness in purpose to the particular application.
    - The original efforts to design and implement high-level languages were driven by the desire to lower the costs of creating software.

3. The cost of **executing programs**:

    - Is greatly influenced by that language’s design.
    - A language that requires many run-time type checks will prohibit fast code execution, regardless of the quality of the compiler.
    - Although execution efficiency was the foremost concern in the design of early languages, it is now considered to be less important.

4. **Compilation cost** vs. **execution speed**

    - **Optimization**:

        - Compilers may use to decrease the size and/or increase the execution speed of the code they produce.
        - If no optimization is done, compilation can be done much faster.

    - Choice:

        - In a laboratory for beginning programming students, who often compile their programs many times during development but use little execution time (their programs are small and they must execute correctly only once), little or no optimization should be done.
        - In a production environment, where compiled programs are executed many times after development, it is better to pay the extra cost to optimize the code.

5. The cost of **poor reliability**:

    - If the software fails in a critical system, such as a nuclear power plant or an X-ray machine for medical use, the cost could be very high.
    - The failures of noncritical systems can also be very expensive in terms of lost future business or lawsuits over defective software systems.

6. The cost of **maintaining programs**:

    - Which includes both corrections and modifications to add new functionality.
    - Depends on a number of language characteristics, primarily readability.
    - Because maintenance is often done by individuals other than the original author of the software, poor readability can make the task extremely challenging.
    - The importance of software maintainability cannot be overstated. It has been estimated that for large software systems with relatively long lifetimes, maintenance costs can be as high as two to four times as much as development costs.

Of all the contributors to language costs, three are most important:

- **Program development**
- **Maintenance**
- **Reliability**

Because these are functions of *writability* and *readability*, these two evaluation criteria are, in turn, the most important.

## Other Criteria

- **Portability**:

    - The ease with which programs can be moved from one implementation to another.
    - Portability is most strongly influenced by the degree of standardization of the language. Some languages are not standardized at all, making programs in these languages very difficult to move from one implementation to another.

- **Generality**:

    - The applicability to a wide range of applications.

- **Well-definedness**:

    - The completeness and precision of the language’s official defining document.

**Language design criteria** are weighed differently from different perspectives.

- Language implementors are concerned primarily with the difficulty of implementing the constructs and features of the language.
- Language users are worried about writability first and readability later.
- Language designers are likely to emphasize elegance and the ability to attract widespread use.

These characteristics often conflict with one another.
