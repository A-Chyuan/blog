# Concurrency in Functional Languages

This section provides a brief overview of support for concurrency in several functional programming languages.

## Multi-LISP

Multi-LISP is an extension to Scheme that allows the programmer to specify program parts that can be executed concurrently. These forms of concurrency are *implicit*; the programmer is simply telling the compiler (or interpreter) some parts of the program that can be run concurrently.

***`pcall` Construct***

One of the ways a programmer can tell the system about possible concurrency is the `pcall` construct. If a function call is embedded in a `pcall` construct, the parameters to the function can be evaluated concurrently.

<div class="alert-example">

Consider the following `pcall` construct:

```lisp
(pcall f a b c d) ; 同時進行 a, b, c, d 的運算
```

The function is `f`, with parameters `a`, `b`, `c`, and `d`.

- The effect of `pcall` is that the parameters of the function can be evaluated concurrently (any or all of the parameters could be complicated expressions).
- Unfortunately, whether this process can be safely used, that is, without affecting the semantics of the function evaluation, is the responsibility of the programmer.

This is actually a simple matter if the language does not allow side effects or if the programmer designed the function not to have side effects or at least to have limited ones. However, Multi-LISP does allow some *side effects*. If the function was not written to avoid side effects, it may be difficult for the programmer to determine whether `pcall` can be safely used.

</div>

***`future` Construct***

The `future` construct of Multi-LISP is a more interesting and potentially more productive source of concurrency.

- As with `pcall`, a function call is wrapped in a `future` construct.
- Such a function is evaluated in a separate thread, with the parent thread continuing its execution.
- The parent thread continues until it needs to use the return value of the function. If the function has not completed its execution when its result is needed, the parent thread waits until it has before it continues.

If a function has two or more parameters, they can also be wrapped in `future` constructs, in which case their evaluations can be done concurrently in separate threads.

These are the only additions to Scheme in Multi-LISP.

## Concurrent ML

Concurrent ML (CML) is an extension to ML that includes a form of threads and a form of synchronous message passing to support concurrency.

***Thread***

- A thread is created in CML with the `spawn` primitive, which takes the function as its parameter. In many cases, the function is specified as an anonymous function.
- As soon as the thread is created, the function begins its execution in the new thread.
- The return value of the function is discarded. The effects of the function are either output produced or through communications with other threads.
- Either the parent thread (the one that spawned the new thread) or the child thread (the new one) could terminate first and it would not affect the execution of the other.

***Message Passing***

Channels provide the means of communicating between threads. A channel is created with the `channel` constructor.

<div class="alert-example">

The following statement creates a channel of arbitrary type named `mychannel`:

```smlnj
let val mychannel = channel()
```

</div>

The two primary operations (functions) on channels are for

- sending (`send`) and
- receiving (`recv`) messages.

The type of the message is inferred from the send operation.

<div class="alert-example">

The following function call sends the integer value 7, and therefore the type of the channel is then inferred to be integer:

```smlnj
send(mychannel, 7)
```

</div>

The `recv` function names the channel as its parameter. Its return value is the value it received.

---

- Because CML communications are synchronous, a message is both sent and received only if both the sender and the receiver are ready.
- If a thread sends a message on a channel and no other thread is ready to receive on that channel, the sender is blocked and waits for another thread to execute a `recv` on the channel.
- Likewise, if a `recv` is executed on a channel by a thread but no other thread has sent a message on that channel, the thread that ran the `recv` is blocked and waits for a message on that channel.

Because channels are types, functions can take them as parameters.

As was the case with Ada’s synchronous message passing,

- an issue with CML synchronous message passing is deciding which message to choose when more than one channel has received one.
- And the same solution is used: the guarded command do-od construct that chooses randomly among messages to different channels.

The synchronization mechanism of CML is the *event*. An explanation of this complicated mechanism is beyond the scope of this chapter (and this book).

## F#

Part of the F# support for concurrency is based on the same .NET classes that are used by C#, specifically `System.Threading.Thread`.

<div class="alert-example">

Suppose we want to run the function `myConMethod` in its own thread. The
following function, when called, will create the thread and start the execution
of the function in the new thread:

```fsharp
let createThread() =
    let newThread = new Thread(myConMethod)
    newThread.Start()
```

</div>

- Recall that in C#, it is necessary to create an instance of a predefined delegate, `ThreadStart`, send its constructor the name of the subprogram, and send the new delegate instance as a parameter to the `Thread` constructor.
- In F#, if a function expects a delegate as its parameter, a lambda expression or a function can be sent and the compiler will behave as if you sent the delegate. So, in the above code, the function `myConMethod` is sent as the parameter to the `Thread` constructor, but what is actually sent is a new instance of `ThreadStart` (to which was sent `myConMethod`).

---

The `Thread` class defines the `Sleep` method, which puts the thread from which it is called to sleep for the number of milliseconds that is sent to it as a parameter.

***Locking***

- Shared immutable data does not require synchronization among the threads that access it.
- However, if the shared data is mutable, which is possible in F#, locking will be required to prevent corruption of the shared data by multiple threads attempting to change it.

A mutable variable can be locked while a function operates on it to provide synchronized access to the object with the `lock` function. This function takes two parameters:

- The first of which is the variable to be changed.
- The second parameter is a lambda expression that changes the variable.

A mutable *heap-allocated variable* is of type `ref`. For example, the following declaration creates such a variable named `sum` with the initial value of 0:

```fsharp
let sum = ref 0
```

- A `ref` type variable can be changed in a lambda expression that uses the ALGOL/Pascal/Ada assignment operator, `:=`.
- The `ref` variable must be prefixed with an exclamation point (`!`) to get its value.

In the following, the mutable variable `sum` is locked while the lambda expression adds the value of `x` to it:

```fsharp
lock(sum) (fun () -> sum := !sum + x)
```

***Asynchronous Calls***

Threads can be called asynchronously, just as with C#, using the same subprograms, `BeginInvoke` and `EndInvoke`, as well as the `IAsyncResult` interface to facilitate the determination of the completion of the execution of the asynchronously called thread.

***Concurrent Generic Collections***

As stated previously, F# has the concurrent generic collections of .NET available to its programs. This can save a great deal of programming effort when building multithreaded programs that need a shared data structure in the form of a queue, stack, or bag.
